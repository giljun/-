# 딥러닝을 사용한 챗봇

## 워드 임베딩

- 신경망을 사용하여 자연어를 처리하려면 우선 컴퓨터가 이해할 수 있는 형식으로 변환
- 가장 쉬운 방법은 One-Hot Encoding을 사용
  - 전체 단어의 수만큼 벡터의 차원을 만들고 각 단어마다 하나의 차원에 대입
  - 해당 방식은 벡터의 차원이 너무 커지기 때문에 학습이 힘들다는 단점이 존재
  - 벡터 표현에 단어와 단어 간의 관계가 전혀 드러나지 않는다는 점
    - "강아지"와 "멍멍이"의 관계가  "강아지"와 "자유주의"간의 관계와 차이가 없다.
    - 두 관계, 모두 다르다라고 취급
- 두번째 방법은 워드 임베딩
  - 0, 1과 같이 두개의 값이 아니라 0~1 사이의 벡터값을 가진다.
  - 하나의 단어마다 각 벡터의 차원을 모두 사용하기 때문에 벡터의 크기를 작게 할 수 있다.
  - 비슷한 단어는 벡터의 값 역시 유사하기 때문에 학습이 더 잘된다는 장점이 있다.
  - 대표적으로는 Word2Vec을 들 수 있는데 신경망을 통해 문서 데이터에서 각 단어의 벡터를 학습



## RNN과 LSTM

- 보통 일반적인 신경망은 피드포워드 방식
- 입력에서 출력까지 한쪽 방향으로만 흐른다.
- 순환 신경망인 RNN(Recurrent Neural Networks)은 출력이 다시 입력으로 들어가는 것이 가장 큰 특징
  - 예를 들면, 신경망은 그림 데이터가 들어오면 어떤 사진인지 분류할 수 있다.
  - 다음 번 그림이 입력되면 바로 전 그림과는 전혀 상관이 없이 다시 처음부터 판단을 한다.
  - 하지만 RNN의 경우, 시간적인 순서가 중요
  - 이전 출력이 다음 출력에 영향을 준다.
    - 주식과 같은 시계열 데이터나 자연어 같이 연속적인 상관관계가 있는 분야에서 많이 사용
- RNN의 가장 큰 단점
  - 입력 데이터 사이의 거리가 멀어질수록 의미를 기억하지 못한다는 것
    - 예를 들어, '철수는 남자다. 그는'이란 문장의 경우, 멋지다란 결과를 내도록 학습할 수가 있다.
    - 그러나 '철수는 남자다. 하지만 나는 여자다. 여자인 나는 아름답다. 그런데 그는'처럼 '철수'와 '그' 사이가 멀 경우에는 문맥을 파악하기가 힘들다.
  - 이러한 문제를 보완하는 것이 LSTM(Long Short Term Memory networks)으로 RNN의 특별한 종류
  - 보통 텐서플로에서 구현을 할 때면 이런 LSTM Cell을 기본으로 사용하게 될 것.



## Seq2Seq

- 딥러닝으로 챗봇을 만드는 한가지 방법은 Seq2Seq(Sequence-to-Sequence) 모델을 사용
- 문장을 그대로 입력 받아서 바로 문장이 출력되도록 하는 방식
- Encoder와 Decoder 두개의 RNN을 사용하여 구현
  - 예를 들어, 'ABC'가 입력으로 들어오면 'WXYZ'가 출력으로 나옵니다.
  - "go"와 "eos"는 시작과 끝을 나타내는 기호
  - "ABC"를 순차적으로 Encoder에 넣고, 그 다음 Decoder에서 결과를 출력
  - 여기서 Decoder의 출력이 다시 입력으로 들어가는 것을 볼 수 있다.
- 구글의 신경망 번역에서도 중요하게 사용되는 중
- 단순한 잡담이 아니라 피자를 주문하거나, 물건을 구입하는 등 여러가지 명령어를 수행하는데는 아직 적합하지 않다는 단점이 존재



## Char-CNN으로 문장의 의도 파악

- 보통 챗봇에서 많이 사용하는 방법은 의도와 개체를 파악하는 것
- 규칙기반과 마찬가지로 딥러닝을 통해서도 이런 방식으로 구현할 수 있다.
- CNN은 대표적으로 이미지 분류에 높은 성능을 보이지만 캐릭터 문자를 처리하는데도 유용
- 문장을 벡터로 변환하고 특징을 추출한 다음 어떤 의도인지 분류를 할 수 있다.
- 딥 러닝의 장점
  - 규칙기반과 다르게 복잡한 구문분석 없이도 문장의 의미를 보다 정확하게 파악할 수 있다는 것
  - 질문 - 답변 데이터만 충분히 확보가 된다면, 앞으로 이런 학습을 통한 방식이 많이 사용되지 않을까 생각합니다.



## RNN으로 개체명 인식 학습

- NER(Named Entity Recognition)은 문장에서 개체명을 인식하는 것을 말합니다.
  - 예를 들어, '피자 4개 서울시청으로 갔다줘'라는 문장에서 다음과 같이 개체명을 뽑아낼 수 있습니다.
  - '피자(음식), 4개(숫자), 서울시청(장소)' 예전부터 HMM이나 SVM 같은 머신러닝 기법으로 개체명을 학습할 수 있었는데, 최근에는 딥러닝이 주로 사용되고 있다.
  - 그 중에서 Bi-LSTM이 좋은 성능을 보인다고 합니다.
- 문장이 입력으로 들어오면 개체명이 출력으로 나옵니다. 예를 들어, '여행 정보 알려줘'는 '여행(B-Travel) 정보(B-Info) 알려줘(O)'로 각각 매칭
- 이렇게 RNN으로 개체명을 학습할 경우 문맥에 따라 보다 정확하게 판단할 수 있다는 장점이 존재
- 단순히 단어로만 개체명을 비교한다면 '애플 파이'와 '애플 컴퓨터'에서 애플의 개체명을 정확히 인식할 수 없다.
- 하지만 RNN은 문장의 순서에 따라 결과가 다르게 나오기 떄문에 둘 사이에 구분이 가능